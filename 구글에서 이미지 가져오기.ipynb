{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 구글에서 이미지 가져오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "참고 웹사이트(변수 설명) (https://icrawler.readthedocs.io/en/latest/builtin.html#search-engine-crawlers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: icrawler in c:\\users\\ibook\\anaconda3\\lib\\site-packages (0.6.2)\n",
      "Requirement already satisfied: lxml in c:\\users\\ibook\\anaconda3\\lib\\site-packages (from icrawler) (4.5.0)\n",
      "Requirement already satisfied: beautifulsoup4>=4.4.1 in c:\\users\\ibook\\anaconda3\\lib\\site-packages (from icrawler) (4.6.0)\n",
      "Requirement already satisfied: requests>=2.9.1 in c:\\users\\ibook\\anaconda3\\lib\\site-packages (from icrawler) (2.23.0)\n",
      "Requirement already satisfied: Pillow in c:\\users\\ibook\\anaconda3\\lib\\site-packages (from icrawler) (7.1.2)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\users\\ibook\\anaconda3\\lib\\site-packages (from icrawler) (1.14.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\ibook\\anaconda3\\lib\\site-packages (from requests>=2.9.1->icrawler) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ibook\\anaconda3\\lib\\site-packages (from requests>=2.9.1->icrawler) (2020.4.5.1)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\ibook\\anaconda3\\lib\\site-packages (from requests>=2.9.1->icrawler) (1.25.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\ibook\\anaconda3\\lib\\site-packages (from requests>=2.9.1->icrawler) (2.9)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install icrawler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: certifi in c:\\users\\ibook\\anaconda3\\lib\\site-packages (2020.4.5.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install certifi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: urllib3[secure] in c:\\users\\ibook\\anaconda3\\lib\\site-packages (1.25.8)\n",
      "Requirement already satisfied: pyOpenSSL>=0.14; extra == \"secure\" in c:\\users\\ibook\\anaconda3\\lib\\site-packages (from urllib3[secure]) (19.1.0)\n",
      "Requirement already satisfied: idna>=2.0.0; extra == \"secure\" in c:\\users\\ibook\\anaconda3\\lib\\site-packages (from urllib3[secure]) (2.9)\n",
      "Requirement already satisfied: certifi; extra == \"secure\" in c:\\users\\ibook\\anaconda3\\lib\\site-packages (from urllib3[secure]) (2020.4.5.1)\n",
      "Requirement already satisfied: cryptography>=1.3.4; extra == \"secure\" in c:\\users\\ibook\\anaconda3\\lib\\site-packages (from urllib3[secure]) (2.9.2)\n",
      "Requirement already satisfied: six>=1.5.2 in c:\\users\\ibook\\anaconda3\\lib\\site-packages (from pyOpenSSL>=0.14; extra == \"secure\"->urllib3[secure]) (1.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: cffi!=1.11.3,>=1.8 in c:\\users\\ibook\\anaconda3\\lib\\site-packages (from cryptography>=1.3.4; extra == \"secure\"->urllib3[secure]) (1.14.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\ibook\\anaconda3\\lib\\site-packages (from cffi!=1.11.3,>=1.8->cryptography>=1.3.4; extra == \"secure\"->urllib3[secure]) (2.20)\n"
     ]
    }
   ],
   "source": [
    "pip install urllib3[secure]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import certifi\n",
    "import urllib3\n",
    "http = urllib3.PoolManager(\n",
    "    cert_reqs='CERT_REQUIRED',\n",
    "    ca_certs=certifi.where())\n",
    "r = http.request('GET', 'http://www.google.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<urllib3.response.HTTPResponse at 0x196cd796860>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "http.request('GET', 'https://www.google.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from icrawler.builtin import BaiduImageCrawler, BingImageCrawler, GoogleImageCrawler  #구글 이미지 크롤러 패키지 다운\n",
    "import os  #경로설정 패키지 'os'\n",
    "image_Tshirts = os.getcwd()  #image_Tshirts라는 변수 안에 현재 작업 디렉토리에서 'T-shirts'라는 새로운 작업 디렉토리를 생성\n",
    "\n",
    "google_crawler = GoogleImageCrawler(\n",
    "feeder_threads=1,\n",
    "parser_threads=1,\n",
    "downloader_threads=4,\n",
    "storage={'root_dir': image_Tshirts})  #긁어올 이미지를 저장할 위치 지정\n",
    "google_crawler.session.verify = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "Filters = dict(\n",
    "    type = 'photo',\n",
    "    size='large',\n",
    "    license = 'commercial,modify',  #수정 후 재사용 가능\n",
    "    date=((2019,7,1),(2020,5,11)))  # 날짜지정 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-11 21:06:55,577 - INFO - icrawler.crawler - start crawling...\n",
      "2020-05-11 21:06:55,578 - INFO - icrawler.crawler - starting 1 feeder threads...\n",
      "2020-05-11 21:06:55,580 - INFO - icrawler.crawler - starting 1 parser threads...\n",
      "2020-05-11 21:06:55,581 - INFO - icrawler.crawler - starting 4 downloader threads...\n",
      "C:\\Users\\ibook\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:1004: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.google.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "2020-05-11 21:06:56,272 - INFO - parser - parsing result page https://www.google.com/search?q=t-shirts&ijn=0&start=0&tbs=&tbm=isch\n",
      "C:\\Users\\ibook\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:1004: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.google.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "2020-05-11 21:06:56,863 - INFO - parser - parsing result page https://www.google.com/search?q=t-shirts&ijn=1&start=100&tbs=&tbm=isch\n",
      "C:\\Users\\ibook\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:1004: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.google.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "2020-05-11 21:06:57,486 - INFO - parser - parsing result page https://www.google.com/search?q=t-shirts&ijn=2&start=200&tbs=&tbm=isch\n",
      "C:\\Users\\ibook\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:1004: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.google.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "2020-05-11 21:06:58,099 - INFO - parser - parsing result page https://www.google.com/search?q=t-shirts&ijn=3&start=300&tbs=&tbm=isch\n",
      "2020-05-11 21:06:58,152 - INFO - feeder - thread feeder-001 exit\n",
      "C:\\Users\\ibook\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:1004: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.google.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "2020-05-11 21:06:58,752 - INFO - parser - parsing result page https://www.google.com/search?q=t-shirts&ijn=4&start=400&tbs=&tbm=isch\n",
      "C:\\Users\\ibook\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:1004: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.google.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "2020-05-11 21:06:59,351 - INFO - parser - parsing result page https://www.google.com/search?q=t-shirts&ijn=5&start=500&tbs=&tbm=isch\n",
      "C:\\Users\\ibook\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:1004: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.google.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "2020-05-11 21:06:59,962 - INFO - parser - parsing result page https://www.google.com/search?q=t-shirts&ijn=6&start=600&tbs=&tbm=isch\n",
      "C:\\Users\\ibook\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:1004: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.google.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "2020-05-11 21:07:00,586 - INFO - downloader - downloader-002 is waiting for new download tasks\n",
      "2020-05-11 21:07:00,588 - INFO - downloader - downloader-001 is waiting for new download tasks\n",
      "2020-05-11 21:07:00,588 - INFO - downloader - downloader-003 is waiting for new download tasks\n",
      "2020-05-11 21:07:00,588 - INFO - downloader - downloader-004 is waiting for new download tasks\n",
      "2020-05-11 21:07:00,611 - INFO - parser - parsing result page https://www.google.com/search?q=t-shirts&ijn=7&start=700&tbs=&tbm=isch\n",
      "C:\\Users\\ibook\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:1004: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.google.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "2020-05-11 21:07:01,280 - INFO - parser - parsing result page https://www.google.com/search?q=t-shirts&ijn=8&start=800&tbs=&tbm=isch\n",
      "C:\\Users\\ibook\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:1004: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.google.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "2020-05-11 21:07:01,938 - INFO - parser - parsing result page https://www.google.com/search?q=t-shirts&ijn=9&start=900&tbs=&tbm=isch\n",
      "2020-05-11 21:07:03,998 - INFO - parser - no more page urls for thread parser-001 to parse\n",
      "2020-05-11 21:07:03,998 - INFO - parser - thread parser-001 exit\n",
      "2020-05-11 21:07:05,589 - INFO - downloader - no more download task for thread downloader-002\n",
      "2020-05-11 21:07:05,590 - INFO - downloader - thread downloader-002 exit\n",
      "2020-05-11 21:07:05,593 - INFO - downloader - no more download task for thread downloader-001\n",
      "2020-05-11 21:07:05,594 - INFO - downloader - thread downloader-001 exit\n",
      "2020-05-11 21:07:05,597 - INFO - downloader - no more download task for thread downloader-003\n",
      "2020-05-11 21:07:05,598 - INFO - downloader - thread downloader-003 exit\n",
      "2020-05-11 21:07:05,600 - INFO - downloader - no more download task for thread downloader-004\n",
      "2020-05-11 21:07:05,601 - INFO - downloader - thread downloader-004 exit\n",
      "2020-05-11 21:07:06,592 - INFO - icrawler.crawler - Crawling task done!\n"
     ]
    }
   ],
   "source": [
    "google_crawler.crawl(keyword='t-shirts', offset=0, max_num=1000,\n",
    "                     min_size=(200,200), filters=None,max_size=None, file_idx_offset=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-11 21:11:47,154 - INFO - icrawler.crawler - start crawling...\n",
      "2020-05-11 21:11:47,155 - INFO - icrawler.crawler - starting 1 feeder threads...\n",
      "2020-05-11 21:11:47,156 - INFO - feeder - thread feeder-001 exit\n",
      "2020-05-11 21:11:47,159 - INFO - icrawler.crawler - starting 1 parser threads...\n",
      "2020-05-11 21:11:47,161 - INFO - icrawler.crawler - starting 1 downloader threads...\n",
      "2020-05-11 21:11:48,106 - INFO - parser - parsing result page https://www.google.com/search?q=%ED%8E%AD%EC%88%98&ijn=0&start=0&tbs=&tbm=isch\n",
      "2020-05-11 21:11:50,165 - INFO - parser - no more page urls for thread parser-001 to parse\n",
      "2020-05-11 21:11:50,167 - INFO - parser - thread parser-001 exit\n",
      "2020-05-11 21:11:52,165 - INFO - downloader - no more download task for thread downloader-001\n",
      "2020-05-11 21:11:52,167 - INFO - downloader - thread downloader-001 exit\n",
      "2020-05-11 21:11:53,168 - INFO - icrawler.crawler - Crawling task done!\n"
     ]
    }
   ],
   "source": [
    "from icrawler.builtin import GoogleImageCrawler\n",
    "import os\n",
    "# 이미지 저장 폴더 경로\n",
    "save_dir = os.path.join('..', '..', '지완')\n",
    "# GoogleImageCrawler 객체 생성\n",
    "google_crawler = GoogleImageCrawler(storage={'root_dir': save_dir})\n",
    "google_crawler.crawl(keyword='펭수', max_num=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
